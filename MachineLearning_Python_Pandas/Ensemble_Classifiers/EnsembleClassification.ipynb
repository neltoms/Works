{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" A majority vote ensemble classifier\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : array-like, shape = [n_classifiers]\n",
    "    Different classifiers for the ensemble\n",
    "    vote : str, {'classlabel', 'probability'}\n",
    "    Default: 'classlabel'\n",
    "    If 'classlabel' the prediction is based on\n",
    "    the argmax of class labels. Else if\n",
    "    'probability', the argmax of the sum of\n",
    "    probabilities is used to predict the class label\n",
    "    (recommended for calibrated classifiers).\n",
    "    weights : array-like, shape = [n_classifiers]\n",
    "    Optional, default: None\n",
    "    If a list of `int` or `float` values are\n",
    "    provided, the classifiers are weighted by\n",
    "    importance; Uses uniform weights if `weights=None`.\n",
    "    \"\"\"\n",
    "def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "    self.classifiers = classifiers\n",
    "    self.named_classifiers = {key: value for\n",
    "    key, value in\n",
    "    _name_estimators(classifiers)}\n",
    "    self.vote = vote\n",
    "    self.weights = weights\n",
    "    \n",
    "def fit(self, X, y):\n",
    "    \n",
    "    \"\"\" Fit classifiers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix},\n",
    "    shape = [n_samples, n_features]\n",
    "    Matrix of training samples.\n",
    "    \n",
    "    y : array-like, shape = [n_samples]\n",
    "    Vector of target class labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    self : object\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Use LabelEncoder to ensure class labels start\n",
    "    # with 0, which is important for np.argmax\n",
    "    # call in self.predict\n",
    "    self.lablenc_ = LabelEncoder()\n",
    "    self.lablenc_.fit(y)\n",
    "    self.classes_ = self.lablenc_.classes_\n",
    "    self.classifiers_ = []\n",
    "    for clf in self.classifiers:\n",
    "        fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "        self.classifiers_.append(fitted_clf)\n",
    "    return self\n",
    "\n",
    "def predict(self, X):\n",
    "    \"\"\" Predict class labels for X.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix},\n",
    "        Shape = [n_samples, n_features]\n",
    "        Matrix of training samples.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    maj_vote : array-like, shape = [n_samples]\n",
    "        Predicted class labels.\n",
    "        \n",
    "    \"\"\"\n",
    "    if self.vote == 'probability':\n",
    "        maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        \n",
    "    else: # 'classlabel' vote\n",
    "        \n",
    "        # Collect results from clf.predict calls\n",
    "        predictions = np.asarray([clf.predict(X)\n",
    "                                  for clf in \n",
    "                                  self.classifiers_]).T\n",
    "\n",
    "        maj_vote = np.apply_along_axis(lambda x:\n",
    "                                       np.argmax(np.bincount(x,\n",
    "                                                             weights=self.weights)),\n",
    "                                                             axis=1,\n",
    "                                                             arr=predictions)\n",
    "    maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "    return maj_vote\n",
    "                                             \n",
    "                                             \n",
    "def predict_proba(self, X):\n",
    "    \"\"\" Predict class probabilities for X.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix},\n",
    "        shape = [n_samples, n_features]\n",
    "        Training vectors, where n_samples is\n",
    "        the number of samples and\n",
    "        n_features is the number of features.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    avg_proba : array-like,\n",
    "        shape = [n_samples, n_classes]\n",
    "        Weighted average probability for\n",
    "        each class per sample.\n",
    "        \n",
    "    \"\"\"\n",
    "    probas = np.asarray([clf.predict_proba(X) \n",
    "                         for clf in self.classifiers_])\n",
    "    avg_proba = np.average(probas, \n",
    "                           axis=0, weights=self.weights)\n",
    "                                             \n",
    "    return avg_proba\n",
    "                                             \n",
    "def get_params(self, deep=True):\n",
    "    \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "    if not deep:\n",
    "        return super(MajorityVoteClassifier, \n",
    "                     self).get_params(deep=False)\n",
    "    else:\n",
    "        out = self.named_classifiers.copy()\n",
    "        for name, step in\\\n",
    "                six.iteritems(self.named_classifiers):\n",
    "            for key, value in six.iteritems(\n",
    "                    step.get_params(deep=True)):\n",
    "                out['%s__%s' % (name, key)] = value\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, [0, 1, 2, 3]], iris.target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "ROC AUC: 0.80 (+/- 0.14) [Logistic Regression]\n",
      "ROC AUC: 0.94 (+/- 0.07) [Decision Tree]\n",
      "ROC AUC: 0.90 (+/- 0.09) [KNN]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(penalty='l2', C=0.001, random_state=0)\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, criterion='entropy', random_state=0)\n",
    "\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([['sc', StandardScaler()], ['clf', clf1]])\n",
    "\n",
    "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
    "\n",
    "clf_labels = ['Logistic Regression', 'Decision Tree', 'KNN']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, \n",
    "                             X=X_train, \n",
    "                             y=y_train, \n",
    "                             cv=10)\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results for multiclass ensemble method w/ Receiver Operator Characteristic area under the curve\n",
    "# The Decision Tree scores improved from 69% at depth 1 to a peak of 94% at depth 4.\n",
    "# I also just realized that I was supposed implement AdaBoost as opposed to the ensemble method with multiclass\n",
    "# classifiers.  I will do that now!\n",
    "# However, the accuracy increased tremendously from last week's estimates due to the increased predictive ability of \n",
    "# multiple classifiers and the use of weighted probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
